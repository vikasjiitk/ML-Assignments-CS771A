             precision    recall  f1-score   support

         -1       0.67      0.40      0.50      2753
          0       0.17      0.01      0.02      1034
          1       0.78      0.95      0.86      9724

avg / total       0.71      0.77      0.72     13511

/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
             precision    recall  f1-score   support

         -1       0.73      0.68      0.71      3053
          0       0.00      0.00      0.00      1063
          1       0.83      0.94      0.89      9395

avg / total       0.74      0.81      0.78     13511

             precision    recall  f1-score   support

         -1       0.61      0.65      0.63      3789
          0       0.18      0.01      0.02      1359
          1       0.76      0.85      0.80      8364

avg / total       0.66      0.71      0.67     13512

             precision    recall  f1-score   support

         -1       0.63      0.62      0.63      3099
          0       0.24      0.01      0.01      1254
          1       0.80      0.91      0.85      9158

avg / total       0.71      0.76      0.72     13511

             precision    recall  f1-score   support

         -1       0.68      0.48      0.56      3941
          0       0.21      0.01      0.02      1739
          1       0.68      0.93      0.79      7832

avg / total       0.62      0.68      0.62     13512

Confusion matrix:
[[ 9495    82  7058]
 [ 1414    47  4988]
 [ 3530   115 40828]]
row=expected, col=predicted

