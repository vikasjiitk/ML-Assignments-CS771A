4
l1
             precision    recall  f1-score   support

        0.0       0.96      0.99      0.98       980
        1.0       0.93      1.00      0.96      1135
        2.0       0.98      0.94      0.96      1032
        3.0       0.96      0.96      0.96      1010
        4.0       0.97      0.94      0.96       982
        5.0       0.96      0.96      0.96       892
        6.0       0.99      0.98      0.98       958
        7.0       0.96      0.94      0.95      1028
        8.0       0.99      0.94      0.96       974
        9.0       0.94      0.96      0.95      1009

avg / total       0.96      0.96      0.96     10000

('Total images labelled:', 10000)
('Images labelled correctly:', 9621)
('Score:', 0.96208755000980295)
Confusion matrix:
[[ 974    1    1    0    0    1    2    1    0    0]
 [   0 1134    1    0    0    0    0    0    0    0]
 [  13   22  971    2    2    0    1   17    4    0]
 [   0    3    5  970    1   13    0    9    6    3]
 [   1   13    0    0  924    0    4    3    0   37]
 [   5    1    0   19    2  853    2    1    1    8]
 [   9    3    0    0    4    3  939    0    0    0]
 [   0   35    4    0    4    0    0  971    0   14]
 [   8    4    3   12    6   12    3    4  917    5]
 [   4    7    2    6    5    5    1    9    2  968]]
(row=expected, col=predicted)
