3
l1
             precision    recall  f1-score   support

        0.0       0.96      0.99      0.98       980
        1.0       0.94      1.00      0.97      1135
        2.0       0.99      0.95      0.97      1032
        3.0       0.97      0.96      0.96      1010
        4.0       0.97      0.95      0.96       982
        5.0       0.96      0.96      0.96       892
        6.0       0.98      0.98      0.98       958
        7.0       0.95      0.96      0.95      1028
        8.0       0.98      0.93      0.96       974
        9.0       0.95      0.95      0.95      1009

avg / total       0.96      0.96      0.96     10000

('Total images labelled:', 10000)
('Images labelled correctly:', 9642)
('Score:', 0.96415367990867984)
Confusion matrix:
[[ 974    1    1    0    0    1    2    1    0    0]
 [   0 1134    1    0    0    0    0    0    0    0]
 [  11   15  979    3    1    0    1   17    5    0]
 [   1    3    3  969    1   14    0    9    5    5]
 [   1   13    0    0  934    0    6    4    0   24]
 [   5    1    0   10    2  856    5    1    3    9]
 [   6    3    0    0    4    3  942    0    0    0]
 [   0   25    3    0    2    0    0  988    0   10]
 [  11    3    3   16    6   13    4    5  908    5]
 [   3    7    0    6   10    3    1   18    3  958]]
(row=expected, col=predicted)
