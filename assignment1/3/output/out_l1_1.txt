1
l1
             precision    recall  f1-score   support

        0.0       0.97      0.99      0.98       980
        1.0       0.95      0.99      0.97      1135
        2.0       0.98      0.96      0.97      1032
        3.0       0.95      0.96      0.95      1010
        4.0       0.97      0.95      0.96       982
        5.0       0.94      0.95      0.95       892
        6.0       0.98      0.98      0.98       958
        7.0       0.96      0.96      0.96      1028
        8.0       0.99      0.92      0.95       974
        9.0       0.94      0.96      0.95      1009

avg / total       0.96      0.96      0.96     10000

('Total images labelled:', 10000)
('Images labelled correctly:', 9631)
('Score:', 0.96303213029111834)
Confusion matrix:
[[ 973    2    1    0    0    1    2    1    0    0]
 [   0 1129    3    0    1    1    1    0    0    0]
 [   9    8  987    6    1    0    2   17    2    0]
 [   0    2    4  965    1   21    0    9    4    4]
 [   1    9    0    0  937    0    3    4    1   27]
 [   2    1    0   17    2  848    9    1    5    7]
 [   5    2    1    0    2    5  943    0    0    0]
 [   0   20    4    2    4    0    0  989    0    9]
 [   9    5    6   21    4   18    3    4  894   10]
 [   1    5    1    7   13    5    1    9    1  966]]
(row=expected, col=predicted)
