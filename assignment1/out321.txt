1
l2
             precision    recall  f1-score   support

        0.0       0.98      0.99      0.99       980
        1.0       0.97      0.99      0.98      1135
        2.0       0.98      0.96      0.97      1032
        3.0       0.96      0.96      0.96      1010
        4.0       0.97      0.96      0.97       982
        5.0       0.95      0.96      0.96       892
        6.0       0.98      0.99      0.98       958
        7.0       0.96      0.96      0.96      1028
        8.0       0.98      0.94      0.96       974
        9.0       0.96      0.96      0.96      1009

avg / total       0.97      0.97      0.97     10000

('Total images labelled:', 10000)
('Images labelled correctly:', 9691)
('Score:', 0.9690691238431085)
Confusion matrix:
[[ 973    1    1    0    0    1    3    1    0    0]
 [   0 1129    3    0    1    1    1    0    0    0]
 [   7    6  992    5    1    0    2   16    3    0]
 [   0    1    2  970    1   19    0    7    7    3]
 [   0    7    0    0  944    0    3    5    1   22]
 [   1    1    0   12    2  860    5    1    6    4]
 [   4    2    0    0    3    5  944    0    0    0]
 [   0   14    6    2    4    0    0  992    0   10]
 [   6    1    3   14    5   13    3    4  920    5]
 [   2    5    1    6   10    5    1   11    1  967]]
(row=expected, col=predicted)
